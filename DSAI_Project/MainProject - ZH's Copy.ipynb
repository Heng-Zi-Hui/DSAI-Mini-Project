{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5dd60a",
   "metadata": {},
   "source": [
    "<div style='color: #216969;\n",
    "           background-color: #EAF6F6;\n",
    "           font-size: 200%;\n",
    "           border-radius:15px;\n",
    "           text-align:center;\n",
    "           font-weight:600;\n",
    "           border-style: solid;\n",
    "           border-color: dark green;\n",
    "           font-family: \"Cambria\";'>\n",
    "Notebook Imports\n",
    "<a class=\"anchor\" id=\"1\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569c4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70ba164",
   "metadata": {},
   "source": [
    "<div style='color: #216969;\n",
    "           background-color: #EAF6F6;\n",
    "           font-size: 200%;\n",
    "           border-radius:15px;\n",
    "           text-align:center;\n",
    "           font-weight:600;\n",
    "           border-style: solid;\n",
    "           border-color: dark green;\n",
    "           font-family: \"Cambria\";'>\n",
    "XGBoost Regression Model\n",
    "<a class=\"anchor\" id=\"1\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37120dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy and Pandas libraries\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "\n",
    "# Import dataset\n",
    "df = pd.read_csv('processedmath.csv')\n",
    "\n",
    "# Make a copy of the dataframe\n",
    "df_copy = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef58b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395, 32)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(395,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "dfX = df.iloc[:, 0:(len(df.columns)-4)] # Features\n",
    "dfy = df.G3 # Target variable\n",
    "print(dfX.shape)\n",
    "print(type(dfX))\n",
    "print(dfy.shape)\n",
    "print(type(dfy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f2a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n"
     ]
    }
   ],
   "source": [
    "# Extract the column names from the two datasets\n",
    "col_names = list(dfX.columns)\n",
    "col_names.append(dfy.name)\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e853c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[ 0  0 18 ...  6  5  6]\n",
      " [ 0  0 17 ...  4  5  5]\n",
      " [ 0  0 15 ... 10  7  8]\n",
      " ...\n",
      " [ 1  1 21 ...  3 10  8]\n",
      " [ 1  1 18 ...  0 11 12]\n",
      " [ 1  1 19 ...  5  8  9]]\n"
     ]
    }
   ],
   "source": [
    "# Conversion from Pandas Dataframe to NumPy Array\n",
    "X = dfX.values\n",
    "y = dfy.values\n",
    "print(type(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b395ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.25, random_state=2)\n",
    "#X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfd3c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Original Model***\n",
      "the training mean squared error is:  2.594534222621698\n",
      "the testing mean squared error is:  3.586443950543177\n"
     ]
    }
   ],
   "source": [
    "xgbR = XGBRegressor(n_estimators = 20, learning_rate = 0.1)\n",
    "xgbR.fit(X_train, y_train.ravel())\n",
    "test_mse_before_tune =  mean_squared_error(xgbR.predict(X_test), y_test)\n",
    "train_mse_before_tune = mean_squared_error(xgbR.predict(X_train), y_train)\n",
    "\n",
    "print('***Original Model***')\n",
    "print('the training mean squared error is: ', train_mse_before_tune)\n",
    "print('the testing mean squared error is: ', test_mse_before_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca402b91",
   "metadata": {},
   "source": [
    "<div style='color: #216969;\n",
    "           background-color: #EAF6F6;\n",
    "           font-size: 200%;\n",
    "           border-radius:15px;\n",
    "           text-align:center;\n",
    "           font-weight:600;\n",
    "           border-style: solid;\n",
    "           border-color: dark green;\n",
    "           font-family: \"Cambria\";'>\n",
    "K-Fold Cross Validation\n",
    "<a class=\"anchor\" id=\"1\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0dcbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  [-2.43194634 -2.56662208 -2.5436719  -2.64672987 -2.62403549]\n",
      "test score:  [-5.76417453 -7.08426513 -4.4863901  -5.57538117 -5.65648791]\n"
     ]
    }
   ],
   "source": [
    "results = cross_validate(xgbR, X, y, scoring='neg_mean_squared_error', cv=5, return_train_score = True)\n",
    "print('train score: ', results['train_score'])\n",
    "print('test score: ', results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "001356ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Original Model***\n",
      "cross val training mean_squared_error is: 2.562601136674392\n",
      "cross val testing mean_squared_error is: 5.713339766111601\n"
     ]
    }
   ],
   "source": [
    "print('***Original Model***')\n",
    "print('cross val training mean_squared_error is:', sum(-results['train_score'])/len(results['train_score']))\n",
    "print('cross val testing mean_squared_error is:', sum(-results['test_score'])/len(results['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3d3d4c",
   "metadata": {},
   "source": [
    "<div style='color: #216969;\n",
    "           background-color: #EAF6F6;\n",
    "           font-size: 200%;\n",
    "           border-radius:15px;\n",
    "           text-align:center;\n",
    "           font-weight:600;\n",
    "           border-style: solid;\n",
    "           border-color: dark green;\n",
    "           font-family: \"Cambria\";'>\n",
    "(Tunning) Statsmodel Ordinary Least Squares\n",
    "<a class=\"anchor\" id=\"1\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8be9515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...  0.  9.  9.]\n",
      " [ 1.  0.  0. ...  2. 10. 10.]\n",
      " [ 1.  1.  1. ...  3. 14. 12.]\n",
      " ...\n",
      " [ 1.  0.  0. ...  2.  8.  6.]\n",
      " [ 1.  0.  0. ...  4. 14. 14.]\n",
      " [ 1.  0.  0. ...  0.  6.  7.]]\n",
      "(296, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   42.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 06 Nov 2022</td> <th>  Prob (F-statistic):</th> <td>1.39e-85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:04:39</td>     <th>  Log-Likelihood:    </th> <td> -608.89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   296</td>      <th>  AIC:               </th> <td>   1284.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   263</td>      <th>  BIC:               </th> <td>   1406.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    32</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.8209</td> <td>    2.470</td> <td>   -0.332</td> <td> 0.740</td> <td>   -5.685</td> <td>    4.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.6755</td> <td>    0.434</td> <td>    1.558</td> <td> 0.120</td> <td>   -0.178</td> <td>    1.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0347</td> <td>    0.284</td> <td>    0.122</td> <td> 0.903</td> <td>   -0.525</td> <td>    0.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.2335</td> <td>    0.119</td> <td>   -1.965</td> <td> 0.051</td> <td>   -0.468</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0361</td> <td>    0.345</td> <td>    0.105</td> <td> 0.917</td> <td>   -0.643</td> <td>    0.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.1970</td> <td>    0.283</td> <td>   -0.697</td> <td> 0.486</td> <td>   -0.754</td> <td>    0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0669</td> <td>    0.395</td> <td>    0.169</td> <td> 0.866</td> <td>   -0.712</td> <td>    0.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.1236</td> <td>    0.150</td> <td>    0.822</td> <td> 0.412</td> <td>   -0.172</td> <td>    0.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0224</td> <td>    0.152</td> <td>    0.147</td> <td> 0.883</td> <td>   -0.277</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0203</td> <td>    0.090</td> <td>    0.225</td> <td> 0.822</td> <td>   -0.158</td> <td>    0.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0461</td> <td>    0.103</td> <td>    0.447</td> <td> 0.655</td> <td>   -0.157</td> <td>    0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1003</td> <td>    0.129</td> <td>    0.775</td> <td> 0.439</td> <td>   -0.155</td> <td>    0.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.2877</td> <td>    0.220</td> <td>   -1.305</td> <td> 0.193</td> <td>   -0.722</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.1525</td> <td>    0.191</td> <td>    0.800</td> <td> 0.425</td> <td>   -0.223</td> <td>    0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.1223</td> <td>    0.169</td> <td>   -0.724</td> <td> 0.469</td> <td>   -0.455</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.2386</td> <td>    0.207</td> <td>    1.151</td> <td> 0.251</td> <td>   -0.170</td> <td>    0.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.5433</td> <td>    0.381</td> <td>    1.427</td> <td> 0.155</td> <td>   -0.206</td> <td>    1.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0647</td> <td>    0.273</td> <td>    0.237</td> <td> 0.813</td> <td>   -0.472</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0567</td> <td>    0.274</td> <td>    0.207</td> <td> 0.836</td> <td>   -0.483</td> <td>    0.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.3451</td> <td>    0.251</td> <td>   -1.376</td> <td> 0.170</td> <td>   -0.839</td> <td>    0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.4850</td> <td>    0.332</td> <td>   -1.460</td> <td> 0.145</td> <td>   -1.139</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.1258</td> <td>    0.613</td> <td>    0.205</td> <td> 0.838</td> <td>   -1.082</td> <td>    1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0577</td> <td>    0.331</td> <td>   -0.174</td> <td> 0.862</td> <td>   -0.709</td> <td>    0.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.3177</td> <td>    0.265</td> <td>   -1.199</td> <td> 0.232</td> <td>   -0.839</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.3168</td> <td>    0.138</td> <td>    2.299</td> <td> 0.022</td> <td>    0.046</td> <td>    0.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    0.1032</td> <td>    0.130</td> <td>    0.792</td> <td> 0.429</td> <td>   -0.154</td> <td>    0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.0074</td> <td>    0.132</td> <td>   -0.056</td> <td> 0.956</td> <td>   -0.268</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -0.1853</td> <td>    0.202</td> <td>   -0.918</td> <td> 0.359</td> <td>   -0.583</td> <td>    0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.1586</td> <td>    0.139</td> <td>    1.143</td> <td> 0.254</td> <td>   -0.114</td> <td>    0.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.0903</td> <td>    0.087</td> <td>    1.038</td> <td> 0.300</td> <td>   -0.081</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.0424</td> <td>    0.016</td> <td>    2.726</td> <td> 0.007</td> <td>    0.012</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    0.2125</td> <td>    0.071</td> <td>    2.991</td> <td> 0.003</td> <td>    0.073</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.9649</td> <td>    0.061</td> <td>   15.801</td> <td> 0.000</td> <td>    0.845</td> <td>    1.085</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>129.071</td> <th>  Durbin-Watson:     </th> <td>   1.851</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 487.604</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.895</td>  <th>  Prob(JB):          </th> <td>1.31e-106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.016</td>  <th>  Cond. No.          </th> <td>    547.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.837\n",
       "Model:                            OLS   Adj. R-squared:                  0.818\n",
       "Method:                 Least Squares   F-statistic:                     42.35\n",
       "Date:                Sun, 06 Nov 2022   Prob (F-statistic):           1.39e-85\n",
       "Time:                        23:04:39   Log-Likelihood:                -608.89\n",
       "No. Observations:                 296   AIC:                             1284.\n",
       "Df Residuals:                     263   BIC:                             1406.\n",
       "Df Model:                          32                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.8209      2.470     -0.332      0.740      -5.685       4.043\n",
       "x1             0.6755      0.434      1.558      0.120      -0.178       1.529\n",
       "x2             0.0347      0.284      0.122      0.903      -0.525       0.595\n",
       "x3            -0.2335      0.119     -1.965      0.051      -0.468       0.001\n",
       "x4             0.0361      0.345      0.105      0.917      -0.643       0.715\n",
       "x5            -0.1970      0.283     -0.697      0.486      -0.754       0.360\n",
       "x6             0.0669      0.395      0.169      0.866      -0.712       0.846\n",
       "x7             0.1236      0.150      0.822      0.412      -0.172       0.420\n",
       "x8             0.0224      0.152      0.147      0.883      -0.277       0.322\n",
       "x9             0.0203      0.090      0.225      0.822      -0.158       0.198\n",
       "x10            0.0461      0.103      0.447      0.655      -0.157       0.249\n",
       "x11            0.1003      0.129      0.775      0.439      -0.155       0.355\n",
       "x12           -0.2877      0.220     -1.305      0.193      -0.722       0.146\n",
       "x13            0.1525      0.191      0.800      0.425      -0.223       0.528\n",
       "x14           -0.1223      0.169     -0.724      0.469      -0.455       0.210\n",
       "x15            0.2386      0.207      1.151      0.251      -0.170       0.647\n",
       "x16            0.5433      0.381      1.427      0.155      -0.206       1.293\n",
       "x17            0.0647      0.273      0.237      0.813      -0.472       0.602\n",
       "x18            0.0567      0.274      0.207      0.836      -0.483       0.597\n",
       "x19           -0.3451      0.251     -1.376      0.170      -0.839       0.149\n",
       "x20           -0.4850      0.332     -1.460      0.145      -1.139       0.169\n",
       "x21            0.1258      0.613      0.205      0.838      -1.082       1.333\n",
       "x22           -0.0577      0.331     -0.174      0.862      -0.709       0.594\n",
       "x23           -0.3177      0.265     -1.199      0.232      -0.839       0.204\n",
       "x24            0.3168      0.138      2.299      0.022       0.046       0.588\n",
       "x25            0.1032      0.130      0.792      0.429      -0.154       0.360\n",
       "x26           -0.0074      0.132     -0.056      0.956      -0.268       0.253\n",
       "x27           -0.1853      0.202     -0.918      0.359      -0.583       0.212\n",
       "x28            0.1586      0.139      1.143      0.254      -0.114       0.432\n",
       "x29            0.0903      0.087      1.038      0.300      -0.081       0.262\n",
       "x30            0.0424      0.016      2.726      0.007       0.012       0.073\n",
       "x31            0.2125      0.071      2.991      0.003       0.073       0.352\n",
       "x32            0.9649      0.061     15.801      0.000       0.845       1.085\n",
       "==============================================================================\n",
       "Omnibus:                      129.071   Durbin-Watson:                   1.851\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              487.604\n",
       "Skew:                          -1.895   Prob(JB):                    1.31e-106\n",
       "Kurtosis:                       8.016   Cond. No.                         547.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The statsmodel.api provides key summary statistics\n",
    "#The lm2 model refers to statsmodel.api model\n",
    "#Add a constant to the X_train dataset and rename it as X_train_sm\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "print(X_train_sm)\n",
    "print(X_train_sm.shape)\n",
    "\n",
    "#Create another model using statsmodel.api using the Ordinary Least Squares (OLS) method for the model\n",
    "lm2 = sm.OLS(y_train, X_train_sm).fit()\n",
    "\n",
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bdfdb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['famrel', 'absences', 'G1', 'G2', 'G3']\n"
     ]
    }
   ],
   "source": [
    "#Using important features (P < 0.05) to evaluate the model\n",
    "dfX_new = df[['famrel', 'absences', 'G1', 'G2']]\n",
    "dfy_new = df.G3\n",
    "col_names = list(dfX_new.columns)\n",
    "col_names.append(dfy_new.name)\n",
    "print(col_names)\n",
    "X = dfX_new.values\n",
    "y = dfy_new.values\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y.ravel(), test_size=0.25, random_state=2)\n",
    "#X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b94521bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***New Model***\n",
      "Training MSE is:  3.6651904351041913\n",
      "Testing MSE is:  3.7391792226623606\n"
     ]
    }
   ],
   "source": [
    "xgbR_new = XGBRegressor(n_estimators = 20, learning_rate = 0.1)\n",
    "xgbR_new.fit(X_train, y_train.ravel())\n",
    "\n",
    "print('***New Model***')\n",
    "print('Training MSE is: ',  mean_squared_error(xgbR_new.predict(X_train), y_train))\n",
    "print('Testing MSE is: ', mean_squared_error(xgbR_new.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5926b",
   "metadata": {},
   "source": [
    "<div style='color: #216969;\n",
    "           background-color: #EAF6F6;\n",
    "           font-size: 200%;\n",
    "           border-radius:15px;\n",
    "           text-align:center;\n",
    "           font-weight:600;\n",
    "           border-style: solid;\n",
    "           border-color: dark green;\n",
    "           font-family: \"Cambria\";'>\n",
    "Grid Search\n",
    "<a class=\"anchor\" id=\"1\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b748a489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9543059058966543\n",
      "{'learning_rate': 0.09, 'max_depth': 2, 'n_estimators': 62}\n"
     ]
    }
   ],
   "source": [
    "mean_squared_error(xgbR_new.predict(X_test), y_test)\n",
    "#DTR = DecisionTreeRegressor(max_depth = 4, min_samples_leaf =1)\n",
    "xgbR_new = XGBRegressor()\n",
    "param_grid = {\n",
    "    \"n_estimators\": range (10,100),\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.09, 0.1, 0.2],\n",
    "    \"max_depth\": [2,4,6,8]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(xgbR_new, param_grid=param_grid, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(-gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08fb8369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Final Model***\n",
      "Training MSE after tuning is:  2.4216796033716963\n",
      "Testing MSE after tuning is:  1.3089113450017726\n",
      "The testing MSE has improved by  0.17285461925000156 after tuning.\n",
      "The testing MSE has improved by  2.2775326055414045 after tuning.\n"
     ]
    }
   ],
   "source": [
    "xgbR_final = XGBRegressor(n_estimators = 62,\n",
    "                          learning_rate = 0.09,\n",
    "                          max_depth = 2)\n",
    "\n",
    "xgbR_final.fit(X_train, y_train.ravel())\n",
    "\n",
    "preds = xgbR_final.predict(X_test)\n",
    "\n",
    "print('***Final Model***')\n",
    "print('Training MSE after tuning is: ', mean_squared_error(xgbR_final.predict(X_train), y_train))\n",
    "print('Testing MSE after tuning is: ', mean_squared_error(xgbR_final.predict(X_test), y_test))\n",
    "print('The testing MSE has improved by ', train_mse_before_tune-mean_squared_error(xgbR_final.predict(X_train), y_train), 'after tuning.')\n",
    "print('The testing MSE has improved by ', test_mse_before_tune-mean_squared_error(xgbR_final.predict(X_test), y_test), 'after tuning.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c9c88",
   "metadata": {},
   "source": [
    "<div style='color: #216969;\n",
    "           background-color: #EAF6F6;\n",
    "           font-size: 200%;\n",
    "           border-radius:15px;\n",
    "           text-align:center;\n",
    "           font-weight:600;\n",
    "           border-style: solid;\n",
    "           border-color: dark green;\n",
    "           font-family: \"Cambria\";'>\n",
    "K-Folds Cross Validation (Final Model)\n",
    "<a class=\"anchor\" id=\"1\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa00407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  [-2.06785415 -2.15221592 -2.23682383 -1.99879505 -1.79611124]\n",
      "test score:  [-2.66085946 -2.36243301 -1.74940083 -3.51992089 -4.43500323]\n"
     ]
    }
   ],
   "source": [
    "results = cross_validate(xgbR_final, X, y.ravel(), scoring='neg_mean_squared_error', cv=5, return_train_score = True)\n",
    "print('train score: ', results['train_score'])\n",
    "print('test score: ', results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dfc453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Final Model***\n",
      "cross val training mean_squared_error is: 2.0503600409315585\n",
      "cross val testing mean_squared_error is: 2.945523483861085\n"
     ]
    }
   ],
   "source": [
    "print('***Final Model***')\n",
    "print('cross val training mean_squared_error is:', sum(-results['train_score'])/len(results['train_score']))\n",
    "print('cross val testing mean_squared_error is:', sum(-results['test_score'])/len(results['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57579e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
